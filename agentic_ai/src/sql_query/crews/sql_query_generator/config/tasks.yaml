query_interpretation_task:
  description: >
    <Task>
      Convert natural language user requests into a clear, structured and logical query plan.
    </Task>

    <Available Tools>
      You have access to these two tools:
      1. **SQLQueryTool**: For executing SQL queries against the database and the distinct values of a column for **IN** queries.
    </Available Tools>

    Today's date is {date}.

    <User Request>
      Here is the user's original request:
      {user_prompt}
    </User Request>

    <Column Description>
      You are provided with the column descriptions of the **Verizon POC schema**:

      **1. Projects Table**
        - project_id (VARCHAR(50), PK): Unique identifier for each project.
        - market (VARCHAR(100)): Market name (e.g., Market A, Market B).
        - site_type (VARCHAR(50)): Raw Land or Colocation.
        - start_date (DATE): Actual project start.
        - end_date_planned (DATE): Planned completion date.
        - end_date_actual (DATE): Actual completion date.
        - Use case: Compare planned vs. actual durations, group by market/site type, filter active vs. completed projects.

      **2. Agents Table**
        - agent_id (SERIAL, PK): Unique ID.
        - agent_name (VARCHAR(100), unique): e.g., RF / Engineering, Real Estate / Leasing, Construction.
        - description (TEXT): Narrative description of the agent’s role.
        - Use case: Join to milestones to attribute tasks to specific functional groups.

      **3. Milestones Table**
        - milestone_id (SERIAL, PK).
        - project_id (VARCHAR(50), FK → Projects).
        - agent_id (INT, FK → Agents).
        - milestone_name (VARCHAR(150)): Name of the milestone.
        - planned_date (DATE): Scheduled milestone completion.
        - actual_date (DATE): Actual completion date.
        - status (VARCHAR(30)): Pending, In Progress, Complete, Delayed.
        - duration_days (INT): Duration in days.
        - anomaly_flag (BOOLEAN): Whether this milestone is anomalous.
        - Use case: Track milestone delays, agent accountability, anomaly detection.

      **4. Dependencies Table**
        - dependency_id (SERIAL, PK).
        - milestone_id (INT, FK → Milestones).
        - prerequisite_id (INT, FK → Milestones).
        - dependency_type (VARCHAR(30)): Prerequisite, Predecessor, Successor.
        - Use case: Build milestone dependency graphs, detect out-of-order tasks.

      **5. Vendors Table**
        - vendor_id (SERIAL, PK).
        - vendor_name (VARCHAR(150), unique).
        - role (VARCHAR(100)): Vendor’s responsibility.
        - Use case: Link vendors to milestones; analyze vendor contribution to delays.

      **6. Milestone_Vendors Table (Join Table)**
        - milestone_id (INT, FK → Milestones).
        - vendor_id (INT, FK → Vendors).
        - contribution (VARCHAR(255)): Notes on vendor role.
        - Use case: Many-to-many link between milestones and vendors.

      **7. Anomalies Table**
        - anomaly_id (SERIAL, PK).
        - milestone_id (INT, FK → Milestones).
        - type (VARCHAR(100)): Missing Date, Long Duration, Vendor Delay, Out-of-Order Dependency.
        - description (TEXT).
        - severity (VARCHAR(20)): Low, Medium, High.
        - detected_on (TIMESTAMP, default CURRENT_TIMESTAMP).
        - Use case: QA monitoring, anomaly trend reporting, linking anomalies to projects/agents/vendors.

      **8. Cycle_Times Table**
        - cycle_id (SERIAL, PK).
        - project_id (VARCHAR(50), FK → Projects).
        - agent_start_id (INT, FK → Agents).
        - agent_end_id (INT, FK → Agents).
        - planned_duration (INT).
        - actual_duration (INT).
        - variance (INT).
        - Use case: Analyze end-to-end cycle efficiency, compare planned vs. actual.
    </Column Description>

    <Previous Execution Error>
      {previous_error}
    </Previous Execution Error>

    <Audience>
      Your audience is a SQL query generator that will use your logical plan to create an accurate SQL query.
    </Audience>

    <Instructions>
      Think like a SQL query planner and break down the user's request into a series of logical steps that can be translated into SQL.

      If <PreviousError> is not None, consider why the previous execution failed and adjust your logical plan accordingly:

        - Avoid previous mistakes.
        - Add additional filters, clarify ambiguous fields, or restructure joins if needed.
        - Suggest alternative aggregations or columns if relevant.

      1. Analyze only data relevant to the user's request.
      2. Determine filters, aggregations, joins, groupings, and ordering.
      3. Whenever you are performing **IN** query on a column, query the column to find the distinct values first.
      4. Resolve ambiguities using column descriptions and table purposes.
      5. Mark field as 'needs_clarification' if ambiguous.
    </Instructions>

    <Show Your Thinking>
      After analyzing the user's request, provide a detailed breakdown of the logical components needed to fulfill the request.
        - What tables did I identify as relevant?
        - What columns are necessary for selection or aggregation?
        - What's missing?
        - Do I have enough information to proceed?
        - Should I search for additional context?
    </Show Your Thinking>

    <Examples>
      (… keep the same three examples you provided …)
    </Examples>
  expected_output: >
    <Output Format>
    {{
        "tables": "All the relevant tables needed for the query",
        "columns": "Specific columns to be selected or aggregated",
        "filters": "Conditions to filter the data",
        "aggregations": "Any aggregations needed (e.g., SUM, COUNT)",
        "joins": "Details of any joins between tables",
        "group_by": "Columns to group the results by",
        "order_by": "Columns to order the results by",
        "unions": "Details of any unions if applicable",
        "case_statements": "Details of any case statements if applicable"
    }}
    </Output Format>
  agent: query_interpretation_agent

query_generation_task:
  description: >
    <Task>
      Convert structured query plan into a syntactically correct, optimized Postgres SQL query.
    </Task>

    Today's date is {date}.

    <Instructions>
      Using the provided logical query plan, generate a syntactically correct and optimized SQL query that fulfills the user's request.
        1. Always generate the SQL in **Postgres format**.
        2. Generate only one SQL query for the plan.
        3. Use explicit JOIN type (INNER, LEFT, RIGHT) as indicated in the plan.
        4. Apply all filters, aggregations, GROUP BY, and ORDER BY accurately.
        5. Only include a GROUP BY clause if the SELECT statement contains aggregate functions (e.g., SUM, COUNT, MAX, MIN, AVG). If no aggregate is used, do not add GROUP BY.
        6. Optimize the query for performance without changing results.
        7. Return ONLY the SQL, nothing else.
        8. Ensure all identifiers match the database metadata exactly.
        9. Always use **lowercase snake_case** for table names, column names, and aliases.
           - Never use capital letters.
           - Never begin with a capital letter.
    </Instructions>

    <Examples>
      (… keep your Example 1 and Example 2 SQL conversions …)
    </Examples>
  expected_output: >
    <Output Format>
      select t1.column1, t2.column2, sum(t1.amount) as total
      from table1 t1
      join table2 t2 on t1.id = t2.ref_id
      where t1.status = 'active'
      group by t1.column1, t2.column2
      order by total desc;
    </Output Format>
  agent: query_generation_agent
  context:
    - query_interpretation_task
